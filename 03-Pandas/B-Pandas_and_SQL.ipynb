{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Pandas together with SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make the graphs a bit prettier, and bigger\n",
    "matplotlib.style.use(['seaborn-talk', 'seaborn-ticks', 'seaborn-whitegrid'])\n",
    "plt.rcParams['figure.figsize'] = (10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the SQLAlchemy library if it is not installed\n",
    "# !sudo -H pip3 install -U sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing into DataFrames using read_sql\n",
    "\n",
    "The `read_sql` function of Pandas allows us to create a dataframe directly from a SQL query. To execute the query, we first setup the connection to the database using the SQLAlchemy library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_string_imdb = 'mysql://{user}:{password}@{host}:{port}/{db}?charset=utf8'.format(\n",
    "    user='student', \n",
    "    password='dwdstudent2015', \n",
    "    host = 'db.ipeirotis.org', \n",
    "    port=3306, \n",
    "    db='imdb',\n",
    "    encoding = 'utf-8'\n",
    ")\n",
    "engine_imdb = create_engine(conn_string_imdb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve the first 10 lines from the actors table \n",
    "\n",
    "Let's start with a simple example. We issue an SQL query, and get back the results loaded in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT * FROM actors LIMIT 10\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actors = pd.read_sql(query, con=engine_imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve the number of movies per year\n",
    "\n",
    "Now let's work on a slightly more advanced example. We want to analyze the number of movies over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT year, COUNT(*) AS num_movies, COUNT(rank) AS rated_movies\n",
    "FROM movies \n",
    "GROUP BY year\n",
    "ORDER BY year\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies = pd.read_sql(query, con=engine_imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to plot the results. In pandas, the simple `plot()` command will use the index as the x-axis, and will plot all the numeric columns, as a line plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The plot() command takes the index (the first \"column\") of the dataframe\n",
    "# and makes that the x-axis.\n",
    "# Then it plots *ALL* the numeric columns as a line\n",
    "df_movies.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not want to plot the `year` variable as a line. So, we select just the other two columns and plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First step: We can eliminate the \"year\" line by selecting \n",
    "# the columns that we want to plot\n",
    "# To select columns, we pass a list of the column names that\n",
    "# we want to keep in square brackets\n",
    "df_movies[ [\"num_movies\", \"rated_movies\"] ].plot() \n",
    "# still the x-axis does not list the year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a couple of issues. We also plotted the year as a line, and we do not have it as the label of the x-axis. For that, we need to convert the year into a proper datetime variable, and then make it the index for the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to make the \"year\" column to be the index\n",
    "\n",
    "# We first convert the column into the right datatype (datetime)\n",
    "df_movies['year'] = pd.to_datetime(df_movies['year'], format='%Y')\n",
    "# And now we specify that the (converted) year column should be the index\n",
    "# The set_index command does not modify the dataframe itself, but rather\n",
    "# it returns a new dataframe with the new index. That's why we save the \n",
    "# result in df_movies2\n",
    "df_movies2 = df_movies.set_index('year')\n",
    "df_movies2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies2.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "* Connect to the Facebook database, and use the `MemberSince` variable from the `Profiles` table to plot the growth of Facebook users. Use the following information:\n",
    ">    user='student', \n",
    ">    password='dwdstudent2015', \n",
    ">    host = 'db.ipeirotis.org', \n",
    ">    port=3306, \n",
    ">    db='facebook'\n",
    "* (_Learn something new_) Use the [cumsum()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.cumsum.html) function of Pandas and plot the total number of registered users over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Examples with SQL and Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run a query to get the political views of Facebook users, broken down by gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_string_fb = 'mysql://{user}:{password}@{host}:{port}/{db}'.format(\n",
    "    user='student', \n",
    "    password='dwdstudent2015', \n",
    "    host = 'db.ipeirotis.org', \n",
    "    port=3306, \n",
    "    db='facebook'\n",
    ")\n",
    "engine_fb = create_engine(conn_string_fb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polviews_by_gender = '''\n",
    "SELECT Sex, PoliticalViews, COUNT(*) AS cnt \n",
    "FROM Profiles \n",
    "WHERE Sex IS NOT NULL AND PoliticalViews IS NOT NULL \n",
    "GROUP BY Sex, PoliticalViews\n",
    "ORDER BY  PoliticalViews, Sex\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's get the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql(polviews_by_gender, con=engine_fb)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now convert the PoliticalViews column into an ordered Categorical variable. This is not strictly necessary, but it will be useful later.\n",
    " It ensures that Political Views appear in an order according to their political spectrum, as opposed to alphabetical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is not strictly necessary, but it will be useful later.\n",
    "# It ensures that Political Views appear in an order according to their\n",
    "# political spectrum, as opposed to alphabetical\n",
    "df[\"PoliticalViews\"] =  pd.Categorical(df[\"PoliticalViews\"], \n",
    "                            categories = ['Very Liberal', 'Liberal', 'Moderate', 'Conservative', 'Very Conservative', 'Libertarian', 'Apathetic', 'Other'], \n",
    "                            ordered=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot this!\n",
    "# Bleh, this is really fugly...\n",
    "# Remember that the index of the dataframe becomes the default x-axis\n",
    "df.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot, baby!\n",
    "# Now the index contains the Political Views, which will be our x-axis\n",
    "dfp = df.pivot_table(index='PoliticalViews', columns='Sex', values='cnt')\n",
    "dfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing values in Pandas\n",
    "\n",
    "Now, let's see a bit how we can normalize the values in Pandas, by performing operations on the columns and rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp.sum() # sums across the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp.sum(axis='index') # sums across the rows (equivalent to dfp.sum() and dfp.sum(axis=0) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp.sum(axis='columns') # this one sums across the columns (axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's normalize the columns, as we have more females than males, and it seems that there are always more women\n",
    "dfp_norm = dfp / dfp.sum()\n",
    "dfp_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of dfp / dfp.sum(), we can also use the .div() method, for dividing the entries with the sum()\n",
    "# Note that, by definition, the dfp / dfp.sum() operation divides  column-wise, not row-wise.\n",
    "dfp_norm = dfp.div( dfp.sum(), axis='columns' )\n",
    "dfp_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now let's do the division by normalizing the values row-wise,\n",
    "# to find the fraction of males/females within each political category\n",
    "dfp_norm2 = dfp.div( dfp.sum(axis='columns'), axis='index' )\n",
    "dfp_norm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_norm.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_norm2.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "a. Use the tables `RelationshipStatus` and `LookingFor`, and show create a plot with a breakdown of what people in different relationship statuses are looking for. To make things more readable (and to practice a bit SQL), remove from the output all combinations that have less than 10 students in them. The plot can use the absolute counts.\n",
    "\n",
    "b. Normalize the results and plot again. To get experience with normalization, try to normalize both by Status (eg \"80% of the people who are in a relationship are looking for Friendship\") and by Relationship Status (eg \"70% of the people who are looking for Random Play are Single\"). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Facebook, Favorite Books, and Political views\n",
    "\n",
    "Now let's do an analysis that examines book preferences and how they correlated with political leanings.\n",
    "\n",
    "We will start by fetching the favorite books for students that declared themselves as Liberal or Conservative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = '''\n",
    "SELECT B.Book, P.PoliticalViews, COUNT(*) AS cnt \n",
    "FROM Profiles P JOIN FavoriteBooks B ON B.ProfileID = P.ProfileId  \n",
    "WHERE PoliticalViews IS NOT NULL AND B.Book IS NOT NULL \n",
    "      AND (PoliticalViews = 'Liberal' OR PoliticalViews = 'Conservative')\n",
    "GROUP BY B.Book, P.PoliticalViews\n",
    "HAVING cnt > 5\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books = pd.read_sql(books, con=engine_fb)\n",
    "df_books.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp = df_books.pivot_table(index='Book', columns='PoliticalViews', values='cnt')\n",
    "dfp.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the `NaN` values for the entries where we had no users falling into that group. Since we will want to do calculations for these books as well, we will use the `fillna` command to fill these entries with a default value (in our case, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the NaN entries with the value 0 \n",
    "dfp = df_books.pivot_table(index='Book', columns='PoliticalViews', values='cnt').fillna(0)\n",
    "dfp.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalization**: We now want to normalize the entries before proceeding further. Let's take a look at the breakdown of political views in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polviews = '''\n",
    "SELECT PoliticalViews, COUNT(*) AS cnt \n",
    "FROM facebook.Profiles\n",
    "GROUP BY PoliticalViews\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polviews = pd.read_sql(polviews, con=engine_fb)\n",
    "df_polviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have many more conservatives than liberals, let's create a new column that calculates the **percentage** of liberal and conservative students that liked each book. For simplicity, we just enter directly the values 6461 (number of liberals) and 936 (number of conservatives). We add the `+1` in the numerator to avoid division by zero later on. _As practice, try to fetch the values 936 and 6461 directly from the database, and automate the calculation._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp[\"Liberal_perc\"] = (dfp[\"Liberal\"] +1)  / 6461\n",
    "dfp[\"Conservative_perc\"] = (dfp[\"Conservative\"] +1)  / 936"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lift\n",
    "\n",
    "Now that we have the normalized values, we can compute the **lift** for each book. The lift is the ratio between the percentage of liberals and the percentage of convervatives. A book with `lift==1` will be equally read by both conservatives and liberals. Books that have lifts significantly higher or lower than 1, reveal preferences to be read by one side of the political spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp[\"lift_liberal\"] = dfp[\"Liberal_perc\"] / dfp[\"Conservative_perc\"]\n",
    "dfp[\"lift_conservative\"] = dfp[\"Conservative_perc\"]  / dfp[\"Liberal_perc\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log-odds\n",
    "\n",
    "One common tranformation is to take the `log` of the lift. We call this metric **log odds**. In that case, the `lift==1` corresponds to a `log_odds` of 0. Negative values indicate negative association, and positive values indicate positive association. A nice property of log-odds is that they are **additive**, which means that summing up log-odds makes (mathematical) sense, under some reasonably general conditions. (The details are beyond the scope of this course, but you can learn more in the data mining class.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dfp[\"log_odds_liberal\"]      =  np.log(dfp[\"lift_liberal\"])\n",
    "dfp[\"log_odds_conservative\"] =  np.log(dfp[\"lift_conservative\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_columns = [\"lift_liberal\", \"log_odds_liberal\", \"lift_conservative\", \"log_odds_conservative\", \"Liberal\", \"Conservative\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liberal_books = (dfp[show_columns]\n",
    "                 .sort_values(\"lift_liberal\", ascending=False)\n",
    "                 .head(10)\n",
    "                )\n",
    "liberal_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conservative_books = (dfp[show_columns]\n",
    "                      .sort_values(\"lift_conservative\", ascending=False)\n",
    "                      .head(10)\n",
    "                     )\n",
    "conservative_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conservative_books.lift_conservative.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liberal_books.lift_liberal.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "We have seen how to compute the log-odds between liberal-conservative for each book. Given this information, we can try to estimate political leanings of students. You can do this by summing the log-odds of their favorite books. \n",
    "\n",
    "Steps: \n",
    "1. Create a table with the log-odds of the books. \n",
    "2. Join the table with the log-odds with the book preferences table.\n",
    "3. Sum the log-odds score for each student.\n",
    "\n",
    "Evaluation:\n",
    "* You have students that have declared their political preferences as Liberal, Conservative, Very Liberal, Very Conservative. Examine the scores for these students, to check how well this technique works. The simplest way is to compute the average (mean) log-odds for students that fall into the different groups. Alternatively, you can try to plot the full distribution of scores.\n",
    "* Calculate a score for all students that did not declare a political view. \n",
    "\n",
    "Notes: \n",
    "* You can do the work in MySQL or in Pandas. If you decide to work purely in Pandas, the [`merge`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.merge.html#pandas.DataFrame.merge) command allows you to perform joins between dataframes, in way similar to SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Inserting Data in a Database using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file\n",
    "restaurants = pd.read_csv('data/restaurant.csv.gz', encoding=\"utf-8\", dtype=\"unicode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usual bookkeeping regarding datatypes\n",
    "restaurants[\"GRADE DATE\"] = pd.to_datetime(restaurants[\"GRADE DATE\"], format=\"%m/%d/%Y\")\n",
    "restaurants[\"RECORD DATE\"] = pd.to_datetime(restaurants[\"RECORD DATE\"], format=\"%m/%d/%Y\")\n",
    "restaurants[\"INSPECTION DATE\"] = pd.to_datetime(restaurants[\"INSPECTION DATE\"], format=\"%m/%d/%Y\")\n",
    "restaurants[\"SCORE\"] = pd.to_numeric(restaurants[\"SCORE\"])\n",
    "restaurants[\"BORO\"] =  pd.Categorical(restaurants[\"BORO\"], ordered=False)\n",
    "restaurants[\"GRADE\"] =  pd.Categorical(restaurants[\"GRADE\"], categories = ['A', 'B', 'C'], ordered=True)\n",
    "restaurants[\"VIOLATION CODE\"] =  pd.Categorical(restaurants[\"VIOLATION CODE\"], ordered=False)\n",
    "restaurants[\"CRITICAL FLAG\"] =  pd.Categorical(restaurants[\"CRITICAL FLAG\"], ordered=False)\n",
    "restaurants[\"ACTION\"] =  pd.Categorical(restaurants[\"ACTION\"], ordered=False)\n",
    "restaurants[\"CUISINE DESCRIPTION\"] =  pd.Categorical(restaurants[\"CUISINE DESCRIPTION\"], ordered=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the MySQL, but without selecting a database\n",
    "conn_string = 'mysql://{user}:{password}@{host}:{port}/?charset=utf8'.format(\n",
    "    user='root', \n",
    "    password='dwdstudent2015', \n",
    "    host = 'localhost', \n",
    "    port=3306, \n",
    "    encoding='utf-8'\n",
    ")\n",
    "engine = create_engine(conn_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the database where we want to store the data\n",
    "# Do not worry about the Warning if the database already exists\n",
    "engine.execute('CREATE DATABASE IF NOT EXISTS nyc_restaurant_inspections')\n",
    "engine.execute('USE nyc_restaurant_inspections')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We drop the table if it is already there\n",
    "engine.execute('DROP TABLE IF EXISTS inspections')\n",
    "# Store the dataframe as a SQL table, using the to_sql command\n",
    "restaurants.to_sql(name='inspections', # name the table \"inspections\"\n",
    "                   con=engine, # use the connection to MySQL created earlier\n",
    "                   if_exists='replace', # if the table is already there, replace it\n",
    "                   index=False, # do not write the index column in the database\n",
    "                   chunksize=1000 # write 1000 lines at a time)\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And then we can just retrieve it from the database\n",
    "df = pd.read_sql(\"SELECT * FROM inspections LIMIT 100\", con=engine)\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We follow the instructions from https://spacy.io/docs/usage/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: spacy in /usr/local/lib/python3.5/dist-packages\n",
      "Requirement already up-to-date: thinc<6.6.0,>=6.5.0 in /usr/local/lib/python3.5/dist-packages (from spacy)\n",
      "Requirement already up-to-date: pip<10.0.0,>=9.0.0 in /usr/local/lib/python3.5/dist-packages (from spacy)\n",
      "Requirement already up-to-date: ftfy<5.0.0,>=4.4.2 in /usr/local/lib/python3.5/dist-packages (from spacy)\n",
      "Requirement already up-to-date: preshed<2.0.0,>=1.0.0 in /usr/local/lib/python3.5/dist-packages (from spacy)\n",
      "Requirement already up-to-date: numpy>=1.7 in /usr/local/lib/python3.5/dist-packages (from spacy)\n",
      "Requirement already up-to-date: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.5/dist-packages (from spacy)\n",
      "Requirement already up-to-date: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.5/dist-packages (from spacy)\n",
      "Requirement already up-to-date: murmurhash<0.27,>=0.26 in /usr/local/lib/python3.5/dist-packages (from spacy)\n",
      "Requirement already up-to-date: six in /usr/local/lib/python3.5/dist-packages (from spacy)\n",
      "Requirement already up-to-date: ujson>=1.35 in /usr/local/lib/python3.5/dist-packages (from spacy)\n",
      "Requirement already up-to-date: pathlib in /usr/local/lib/python3.5/dist-packages (from spacy)\n",
      "Requirement already up-to-date: dill<0.3,>=0.2 in /usr/local/lib/python3.5/dist-packages (from spacy)\n",
      "Requirement already up-to-date: regex<2017.12.1,>=2017.4.1 in /usr/local/lib/python3.5/dist-packages (from spacy)\n",
      "Requirement already up-to-date: cymem<1.32,>=1.30 in /usr/local/lib/python3.5/dist-packages (from spacy)\n",
      "Requirement already up-to-date: wrapt in /usr/local/lib/python3.5/dist-packages (from thinc<6.6.0,>=6.5.0->spacy)\n",
      "Requirement already up-to-date: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.5/dist-packages (from thinc<6.6.0,>=6.5.0->spacy)\n",
      "Requirement already up-to-date: cytoolz<0.9,>=0.8 in /usr/local/lib/python3.5/dist-packages (from thinc<6.6.0,>=6.5.0->spacy)\n",
      "Requirement already up-to-date: termcolor in /usr/local/lib/python3.5/dist-packages (from thinc<6.6.0,>=6.5.0->spacy)\n",
      "Requirement already up-to-date: html5lib in /usr/local/lib/python3.5/dist-packages (from ftfy<5.0.0,>=4.4.2->spacy)\n",
      "Requirement already up-to-date: wcwidth in /usr/local/lib/python3.5/dist-packages (from ftfy<5.0.0,>=4.4.2->spacy)\n",
      "Requirement already up-to-date: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.5/dist-packages (from requests<3.0.0,>=2.13.0->spacy)\n",
      "Requirement already up-to-date: idna<2.7,>=2.5 in /usr/local/lib/python3.5/dist-packages (from requests<3.0.0,>=2.13.0->spacy)\n",
      "Requirement already up-to-date: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.5/dist-packages (from requests<3.0.0,>=2.13.0->spacy)\n",
      "Requirement already up-to-date: certifi>=2017.4.17 in /usr/local/lib/python3.5/dist-packages (from requests<3.0.0,>=2.13.0->spacy)\n",
      "Requirement already up-to-date: toolz>=0.8.0 in /usr/local/lib/python3.5/dist-packages (from cytoolz<0.9,>=0.8->thinc<6.6.0,>=6.5.0->spacy)\n",
      "Requirement already up-to-date: setuptools>=18.5 in /usr/local/lib/python3.5/dist-packages (from html5lib->ftfy<5.0.0,>=4.4.2->spacy)\n",
      "Requirement already up-to-date: webencodings in /usr/local/lib/python3.5/dist-packages (from html5lib->ftfy<5.0.0,>=4.4.2->spacy)\n"
     ]
    }
   ],
   "source": [
    "!sudo -H python3 -m pip install -U spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support for english\n",
    "!sudo python3 -m spacy.en.download all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support for german\n",
    "!sudo python3 -m spacy.de.download all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting with Spacy\n",
    "\n",
    "We first import the library and create an `nlp` variable, instantiated for English (`'en'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the space library, instantiated for English\n",
    "#note: the first time you run spaCy in a file it takes a little while to load up its modules\n",
    "nlp = spacy.load('en') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From https://nicschrading.com/project/Intro-to-NLP-with-spaCy/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"There is an art, it says, or rather, a knack to flying. \n",
    "The knack lies in learning how to throw yourself at the ground and miss.\n",
    "In the beginning the Universe was created. This has made a lot of people\n",
    "very angry and been widely regarded as a bad move.\n",
    "This Prof. Panos, Ph.D. costs $12,345.67\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all you have to do to parse text is this:\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [token for token in doc]\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the tokens\n",
    "# All you have to do is iterate through the doc\n",
    "# Each token is an object with lots of different properties\n",
    "# A property with an underscore at the end returns the string representation\n",
    "# while a property without the underscore returns an index (int) into spaCy's vocabulary\n",
    "# The probability estimate is based on counts from a 3 billion word corpus\n",
    "for i, token in enumerate(doc):\n",
    "    print(\"original:\", token.orth, token.orth_)\n",
    "    print(\"lowercased:\", token.lower, token.lower_)\n",
    "    print(\"lemma:\", token.lemma, token.lemma_)\n",
    "    print(\"shape:\", token.shape, token.shape_)\n",
    "    print(\"prefix:\", token.prefix, token.prefix_)\n",
    "    print(\"suffix:\", token.suffix, token.suffix_)\n",
    "    print(\"part of speech:\", token.pos_)\n",
    "    print(\"log probability:\", token.prob)\n",
    "    print(\"Brown cluster id:\", token.cluster)\n",
    "    print(\"----------------------------------------\")\n",
    "    if i > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get some data\n",
    "\n",
    "First let's get a few text files, so that we can run our examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data\n",
    "!curl -L 'https://raw.githubusercontent.com/cytora/pycon-nlp-in-10-lines/master/data/article.txt' -o data/article.txt\n",
    "!curl -L 'https://raw.githubusercontent.com/cytora/pycon-nlp-in-10-lines/master/data/pride_and_prejudice.txt' -o data/pride_and_prejudice.txt\n",
    "!curl -L 'https://raw.githubusercontent.com/cytora/pycon-nlp-in-10-lines/master/data/rand-terrorism-dataset.txt'  -o data/rand-terrorism-dataset.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will read the text file and then we will use the `nlp` object from spacy to analyze the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"data/article.txt\"\n",
    "text = open(filename, 'r').read()\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Print tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print tokens, one token per line\n",
    "# The enumerate function is just used to add a counter\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Print Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first 5 sentences (one sentence per line)\n",
    "# The enumerate function is just used to add a counter\n",
    "for i, sent in enumerate(doc.sents):\n",
    "    print(i, \"==>\", sent)\n",
    "    if i>5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Named Entities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = set([ent.lemma_ for ent in doc.ents])\n",
    "# entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''JPMorgan rose 0.45% to 95.03 in the stock market today. Intraday shares rose as high as 95.37, briefly clearing a 95.32 flat base buy point. Volume was light.\n",
    "Bank of America, whose large U.S. operations make it sensitive to the Fed's rate hikes, is in a shallow base with a 25.45 buy point. BofA shares edged up 0.4% to 25.16.\n",
    "Morgan Stanley is in a shallow base with a 49 buy point. Morgan Stanley climbed 0.8% to 48.26.\n",
    "PNC Financial Services cleared a flat base with a 133.36 buy point for most of the session, but closed up 0.3% to 133.35, a penny below that mark. PNC also topped that entry intraday Wednesday, but closed just below that level.\n",
    "Citigroup rose 0.4% to 71.76. Citigroup is still in buy range after clearing a 69.96 flat-base entry on Monday.'''\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bank of america # ORG',\n",
       " 'citigroup # ORG',\n",
       " 'fed # ORG',\n",
       " 'morgan stanley # ORG',\n",
       " 'pnc # ORG',\n",
       " 'pnc financial services # ORG'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities_with_type = set([ent.lemma_+\" # \"+ent.label_ for ent in doc.ents if ent.label_=='ORG' ])\n",
    "entities_with_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Noun chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jpmorgan',\n",
       " 'the stock market',\n",
       " 'intraday share',\n",
       " 'a 95.32 flat base buy point',\n",
       " 'volume',\n",
       " 'bank',\n",
       " 'america',\n",
       " 'large u.s. operation',\n",
       " '-PRON-',\n",
       " \"the fed 's rate hike\",\n",
       " 'a shallow base',\n",
       " 'a 25.45 buy point',\n",
       " 'bofa share',\n",
       " 'a shallow base',\n",
       " 'a 49 buy point',\n",
       " 'a flat base',\n",
       " 'a 133.36 buy point',\n",
       " 'the session',\n",
       " 'that mark',\n",
       " 'that entry intraday',\n",
       " 'that level',\n",
       " 'range',\n",
       " 'a 69.96 flat - base entry']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = [chunk.lemma_ for chunk in doc.noun_chunks if chunk.lemma_ not in entities]\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a shallow base', 2),\n",
       " ('-PRON-', 1),\n",
       " ('a 49 buy point', 1),\n",
       " ('a 95.32 flat base buy point', 1),\n",
       " ('that level', 1),\n",
       " ('jpmorgan', 1),\n",
       " ('a flat base', 1),\n",
       " ('volume', 1),\n",
       " (\"the fed 's rate hike\", 1),\n",
       " ('a 133.36 buy point', 1),\n",
       " ('a 25.45 buy point', 1),\n",
       " ('bofa share', 1),\n",
       " ('a 69.96 flat - base entry', 1),\n",
       " ('intraday share', 1),\n",
       " ('bank', 1),\n",
       " ('the session', 1),\n",
       " ('that mark', 1),\n",
       " ('america', 1),\n",
       " ('that entry intraday', 1),\n",
       " ('range', 1)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "keywords = Counter()\n",
    "for chunk in chunks:\n",
    "    # print(chunk, nlp.vocab[chunk].prob )\n",
    "    if nlp.vocab[chunk].prob < -8: # probablity value -8 is arbitrarily selected threshold\n",
    "        keywords[chunk] += 1\n",
    "\n",
    "keywords.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45% to - 0.45% to - 1.0000000021195457\n",
      "0.45% to - as high as 95.37, briefly - 0.5840479437952512\n",
      "0.45% to - 0.4% to - 1.0000000021195457\n",
      "0.45% to - 0.8% to - 1.0000000021195457\n",
      "0.45% to - 0.3% to - 1.0000000021195457\n",
      "0.45% to - 0.4% to - 1.0000000021195457\n",
      "today - today - 0.9999999639922463\n",
      "today - as high as 95.37, briefly - 0.5182494980459993\n",
      "as high as 95.37, briefly - 0.45% to - 0.5840479437952512\n",
      "as high as 95.37, briefly - today - 0.5182494980459993\n",
      "as high as 95.37, briefly - as high as 95.37, briefly - 0.9999999697445826\n",
      "as high as 95.37, briefly - 0.4% to - 0.5840479437952512\n",
      "as high as 95.37, briefly - 0.8% to - 0.5840479437952512\n",
      "as high as 95.37, briefly - 0.3% to - 0.5840479437952512\n",
      "as high as 95.37, briefly - 0.4% to - 0.5840479437952512\n",
      "Bank of America - Bank of America - 1.0000000042989907\n",
      "Bank of America - PNC Financial Services - 0.58372110136483\n",
      "Fed - Fed - 0.9999999493994777\n",
      "0.4% to - 0.45% to - 1.0000000021195457\n",
      "0.4% to - as high as 95.37, briefly - 0.5840479437952512\n",
      "0.4% to - 0.4% to - 1.0000000021195457\n",
      "0.4% to - 0.8% to - 1.0000000021195457\n",
      "0.4% to - 0.3% to - 1.0000000021195457\n",
      "0.4% to - 0.4% to - 1.0000000021195457\n",
      "0.8% to - 0.45% to - 1.0000000021195457\n",
      "0.8% to - as high as 95.37, briefly - 0.5840479437952512\n",
      "0.8% to - 0.4% to - 1.0000000021195457\n",
      "0.8% to - 0.8% to - 1.0000000021195457\n",
      "0.8% to - 0.3% to - 1.0000000021195457\n",
      "0.8% to - 0.4% to - 1.0000000021195457\n",
      "PNC Financial Services - Bank of America - 0.58372110136483\n",
      "PNC Financial Services - PNC Financial Services - 1.0000000136177527\n",
      "0.3% to - 0.45% to - 1.0000000021195457\n",
      "0.3% to - as high as 95.37, briefly - 0.5840479437952512\n",
      "0.3% to - 0.4% to - 1.0000000021195457\n",
      "0.3% to - 0.8% to - 1.0000000021195457\n",
      "0.3% to - 0.3% to - 1.0000000021195457\n",
      "0.3% to - 0.4% to - 1.0000000021195457\n",
      "0.4% to - 0.45% to - 1.0000000021195457\n",
      "0.4% to - as high as 95.37, briefly - 0.5840479437952512\n",
      "0.4% to - 0.4% to - 1.0000000021195457\n",
      "0.4% to - 0.8% to - 1.0000000021195457\n",
      "0.4% to - 0.3% to - 1.0000000021195457\n",
      "0.4% to - 0.4% to - 1.0000000021195457\n"
     ]
    }
   ],
   "source": [
    "for ent1 in doc.ents:\n",
    "    for ent2 in doc.ents:\n",
    "        similarity = ent1.similarity(ent2)\n",
    "        if similarity > 0.5:\n",
    "            print('{} - {} - {}' .format(ent1, ent2, similarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------\n",
      "Top 3 closest results:\n",
      "Recall\n",
      "Pride\n",
      "Phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# cosine similarity\n",
    "cosine = lambda v1, v2: dot(v1, v2) / (norm(v1) * norm(v2))\n",
    "\n",
    "# Let's see if it can figure out this analogy\n",
    "# B is to A as C is to ???\n",
    "a = nlp.vocab['London']\n",
    "b = nlp.vocab['UK']\n",
    "c = nlp.vocab['France']\n",
    "\n",
    "result = a.vector - b.vector + c.vector\n",
    "\n",
    "# gather all known words, take only the lowercased versions\n",
    "allWords = list({w for w in nlp.vocab if w.has_vector and w.is_title and w.lower_ not in set({a.lower_,b.lower_,c.lower_})})\n",
    "# sort by similarity to the result\n",
    "allWords.sort(key=lambda w: cosine(w.vector, result))\n",
    "allWords.reverse()\n",
    "print(\"\\n----------------------------\\nTop 3 closest results:\")\n",
    "for word in allWords[:3]:   \n",
    "    print(word.orth_)\n",
    "    \n",
    "# it got it! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"data/rand-terrorism-dataset.txt\"\n",
    "text = open(filename, 'r').read()\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"data/pride_and_prejudice.txt\"\n",
    "text = open(filename, 'r').read()\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
